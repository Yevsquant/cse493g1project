{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnOq2mqIWNu-",
        "outputId": "62a02dc3-bbb1-4177-99c5-60918ff5d77f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cse493g1/assignments/assignment2/'\n",
        "FOLDERNAME = 'cse493g1/cse493g1project/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it.\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from model_trainer import Trainer\n",
        "from Model import GraphCaptioningModel\n",
        "from model_utils import decode_captions, create_minibatch, encode_captions"
      ],
      "metadata": {
        "id": "nsgDVfpFbOcw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import re\n",
        "\n",
        "class GraphImageDataset(Dataset):\n",
        "    def __init__(self, csv_files, transform=None):\n",
        "        self.data = pd.concat([pd.read_csv(file) for file in csv_files], ignore_index=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      x, y = self.data.iloc[idx]\n",
        "      x_out = str(x)\n",
        "      y_out = str(y)\n",
        "      return x_out, y_out\n",
        "\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor"
      ],
      "metadata": {
        "id": "YDZOK295369h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_files2 = ['/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_kk0.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_cr0.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_gv0.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_sp0.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_kk0_medium.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_cr0_medium.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_gv0_medium.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_sp0_medium.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_kk1.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_cr1.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_gv1.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_small/data_sp1.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_kk1_medium.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_cr1_medium.csv',\n",
        "              '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_gv1_medium.csv', '/content/drive/My Drive/cse493g1/cse493g1project/datasets/datasets_medium/data_sp1_medium.csv']\n",
        "\n",
        "dataset_mixed = GraphImageDataset(csv_files=csv_files2)"
      ],
      "metadata": {
        "id": "ALLxNpY11XL7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PIL\n",
        "import torchvision.transforms.functional as F\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.io import read_image\n",
        "import torchvision.transforms as transform\n",
        "from pathlib import Path\n",
        "\n",
        "raw_data_clr = {}\n",
        "clr_len = dataset_mixed.__len__()\n",
        "\n",
        "graph_list = []\n",
        "caption_list = []\n",
        "for i in np.random.choice(clr_len, 2000):\n",
        "  graph_path, caption = dataset_mixed.__getitem__(i)\n",
        "  graph = F.pil_to_tensor(PIL.Image.open('/content/drive/My Drive/cse493g1/cse493g1project/datasets' + graph_path).convert('RGB'))\n",
        "  graph_list.append(np.array([graph.numpy()]).reshape(graph.shape))\n",
        "  caption_list.append(caption)\n",
        "raw_data_clr['features'] = np.array(graph_list)\n",
        "raw_data_clr['captions'] = np.array(caption_list)"
      ],
      "metadata": {
        "id": "wfrHKcsSCBiM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('/content/drive/My Drive/cse493g1/cse493g1project/color_features.json', 'w', encoding ='utf8') as json_file:\n",
        "  json.dump(raw_data_clr['features'], json_file, ensure_ascii = True)\n",
        "\n",
        "with open('/content/drive/My Drive/cse493g1/cse493g1project/color_captions.json', 'w', encoding ='utf8') as json_file:\n",
        "  json.dump(raw_data_clr['captions'], json_file, ensure_ascii = True)"
      ],
      "metadata": {
        "id": "KAYMKl0g_1x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"MIXED COLOR DATA\")\n",
        "\n",
        "print(raw_data_clr['features'].shape)\n",
        "print(raw_data_clr['features'][0])\n",
        "print(raw_data_clr['features'][0].shape)\n",
        "print(raw_data_clr['captions'].shape)\n",
        "print(raw_data_clr['captions'][0])\n",
        "print(raw_data_clr['captions'][0].shape)"
      ],
      "metadata": {
        "id": "oyJ7J3u5IHYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## THIS BLOCK WAS JUST FOR TESTING, THE NEXT BLOCK IS THE ACTUAL TRAINING CODE ##\n",
        "\n",
        "from model_trainer import Trainer\n",
        "from Model import GraphCaptioningModel\n",
        "from model_utils import decode_captions, create_minibatch, encode_captions\n",
        "\n",
        "data = {}\n",
        "\n",
        "data['idx_to_word'] = ['<NULL>', '<START>', '<END>']\n",
        "for i in range(100):\n",
        "  data['idx_to_word'].append(str(i))\n",
        "punc = ['{', '}', '[', ']', '(', ')', ':', ',', ' ']\n",
        "for p in punc:\n",
        "  data['idx_to_word'].append(p)\n",
        "\n",
        "data['word_to_idx'] = {}\n",
        "for i in range(len(data['idx_to_word'])):\n",
        "  data['word_to_idx'][data['idx_to_word'][i]] = i\n",
        "\n",
        "data['train_captions'] = torch.tensor(encode_captions(raw_data['captions'], data['word_to_idx'])).type(dtype)\n",
        "data['train_features'] = torch.tensor(np.array([raw_data['features']])).type(dtype)\n",
        "print(data['train_features'].shape)\n",
        "print(data['train_captions'].shape)\n",
        "\n",
        "transformer = GraphCaptioningModel(\n",
        "          word_to_idx=data['word_to_idx'],\n",
        "          wordvec_dim=256,\n",
        "          max_length=2000\n",
        "        ).type(dtype)\n",
        "\n",
        "\n",
        "transformer_solver = Trainer(transformer, data, idx_to_word=data['idx_to_word'],\n",
        "           num_epochs=10,\n",
        "           batch_size=1,\n",
        "           learning_rate=0.001,\n",
        "           verbose=True, print_every=10,\n",
        "         )\n",
        "\n",
        "transformer_solver.train()\n",
        "\n",
        "# Plot the training losses.\n",
        "plt.plot(transformer_solver.loss_history)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss history')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SMcZiFa2IQSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model_trainer import Trainer\n",
        "from Model import GraphCaptioningModel\n",
        "from model_utils import decode_captions, create_minibatch, encode_captions\n",
        "\n",
        "torch.manual_seed(493)\n",
        "np.random.seed(493)\n",
        "\n",
        "\n",
        "data_clr = {}\n",
        "\n",
        "data_clr['idx_to_word'] = ['<NULL>', '<START>', '<END>']\n",
        "for i in range(100):\n",
        "  data_clr['idx_to_word'].append(str(i))\n",
        "punc = ['{', '}', '[', ']', '(', ')', ':', ',', ' ']\n",
        "for p in punc:\n",
        "  data_clr['idx_to_word'].append(p)\n",
        "\n",
        "data_clr['word_to_idx'] = {}\n",
        "for i in range(len(data_clr['idx_to_word'])):\n",
        "  data_clr['word_to_idx'][data_clr['idx_to_word'][i]] = i\n",
        "\n",
        "tenth = len(raw_data_clr)//10\n",
        "\n",
        "encoded_captions = encode_captions(raw_data_clr['captions'], data_clr['word_to_idx'])\n",
        "\n",
        "data_clr['train_captions'] = torch.tensor(encoded_captions[:tenth*8]).type(dtype)\n",
        "data_clr['train_features'] = torch.tensor(raw_data_clr['features'][:tenth*8]).type(dtype)\n",
        "\n",
        "data_clr['val_captions'] = torch.tensor(encoded_captions[tenth*8:tenth*9]).type(dtype)\n",
        "data_clr['val_features'] = torch.tensor(raw_data_clr['features'][tenth*8:tenth*9]).type(dtype)\n",
        "\n",
        "data_clr['test_captions'] = torch.tensor(encoded_captions[tenth*9:]).type(dtype)\n",
        "data_clr['test_features'] = torch.tensor(raw_data_clr['features'][tenth*9:]).type(dtype)\n",
        "\n",
        "\n",
        "graph_model_clr = GraphCaptioningModel(\n",
        "          word_to_idx=data['word_to_idx'],\n",
        "          wordvec_dim=256,\n",
        "          max_length=1600\n",
        "        ).type(dtype)\n",
        "\n",
        "\n",
        "model_solver_clr = Trainer(graph_model_clr, data_clr, idx_to_word=data['idx_to_word'],\n",
        "           num_epochs=10,\n",
        "           batch_size=10,\n",
        "           learning_rate=0.001,\n",
        "           verbose=True, print_every=10,\n",
        "         )\n",
        "\n",
        "model_solver_clr.train()\n",
        "\n",
        "# Plot the training losses.\n",
        "plt.plot(model_solver_clr.loss_history)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training loss history')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZT_DHS1wauox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for split in ['train', 'val']:\n",
        "    minibatch = create_minibatch(data, split=split, batch_size=2)\n",
        "    gt_captions, features = minibatch\n",
        "    gt_captions = decode_captions(gt_captions, data_clr['idx_to_word'])\n",
        "\n",
        "    sample_captions = transformer.sample(features, max_length=1600)\n",
        "    sample_captions = decode_captions(sample_captions, data_clr['idx_to_word'])\n",
        "\n",
        "    for gt_caption, sample_caption, features in zip(gt_captions, sample_captions, features):\n",
        "        # Skip missing URLs.\n",
        "        plt.imshow(features)\n",
        "        plt.title('%s\\n%s\\nGT:%s' % (split, sample_caption, gt_caption))\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "BE4-fC4Tavdo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
